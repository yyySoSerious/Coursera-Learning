{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc82526a-8f21-43d0-812a-76dd337677fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#After executing the cell,please RESTART the kernel and run all the cells.\n",
    "!pip install --user \"langchain-community==0.2.1\"\n",
    "!pip install --user \"pypdf==4.2.0\"\n",
    "!pip install --user \"PyMuPDF==1.24.5\"\n",
    "!pip install --user \"unstructured==0.14.8\"\n",
    "!pip install --user \"markdown==3.6\"\n",
    "!pip install --user  \"jq==1.7.0\"\n",
    "!pip install --user \"pandas==2.2.2\"\n",
    "!pip install --user \"docx2txt==0.8\"\n",
    "!pip install --user \"requests==2.32.3\"\n",
    "!pip install --user \"beautifulsoup4==4.12.3\"\n",
    "!pip install --user \"nltk==3.8.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402a683-c624-47b8-8f53-63443c8d3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user \"ibm-watsonx-ai==1.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d8e4ee-fce3-48a5-8b70-9bdb494b62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --user \"langchain-ibm==0.1.11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67a7715-9ec5-4afc-813f-7d6514dda370",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --user \"chromadb==0.4.24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f00c34-f0eb-4ccc-9a31-0cd8b63d2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders.csv_loader import UnstructuredCSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bd8eb-44df-4274-8c9c-ced64ecf9044",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5d6955-53ad-42b0-883e-82f0bb31455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A Comprehensive Review of Low-Rank\\n'\n",
      " 'Adaptation in Large Language Models for\\n'\n",
      " 'Efficient Parameter Tuning\\n'\n",
      " 'September 10, 2024\\n'\n",
      " 'Abstract\\n'\n",
      " 'Natural Language Processing (NLP) often involves pre-training large\\n'\n",
      " 'models on extensive datasets and then adapting them for specific tasks\\n'\n",
      " 'through fine-tuning. However, as these models grow larger, like GPT-3\\n'\n",
      " 'with 175 billion parameters, fully fine-tuning them becomes computa-\\n'\n",
      " 'tionally expensive. We propose a novel method called LoRA (Low-Rank\\n'\n",
      " 'Adaptation) that significantly reduces the overhead by freezing the orig-\\n'\n",
      " 'inal model weights and only training small rank decomposition matrices.\\n'\n",
      " 'This leads to up to 10,000 times fewer trainable parameters and reduces\\n'\n",
      " 'GPU memory usage by three times. LoRA not only maintains but some-\\n'\n",
      " 'times surpasses fine-tuning performance on models like RoBERTa, De-\\n'\n",
      " 'BERTa, GPT-2, and GPT-3. Unlike other methods, LoRA introduces\\n'\n",
      " 'no extra latency during inference, making it more efficient for practical\\n'\n",
      " 'applications. All relevant code an')\n"
     ]
    }
   ],
   "source": [
    "paper_link = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WgM1DaUn2SYPcCg_It57tA/A-Comprehensive-Review-of-Low-Rank-Adaptation-in-Large-Language-Models-for-Efficient-Parameter-Tuning-1.pdf\"\n",
    "loader = PyPDFLoader(paper_link)\n",
    "data = loader.load_and_split()\n",
    "pprint(data[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0b22a-b078-4b4e-bc26-8c7fbb742b83",
   "metadata": {},
   "source": [
    "## Apply Text Splitting Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100fd27b-bb9b-42cf-9786-923efe20e24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\\\documentclass{article}\\n\\n    \\x08egin{document}'),\n",
       " Document(page_content='\\\\maketitle\\n\\n    \\\\section{Introduction}\\n\\n    Large language'),\n",
       " Document(page_content='models (LLMs) are a type of machine learning model that can'),\n",
       " Document(page_content='be trained on vast amounts of text data to generate'),\n",
       " Document(page_content='human-like language. In recent years, LLMs have made'),\n",
       " Document(page_content='significant advances in various natural language processing'),\n",
       " Document(page_content='tasks, including language translation, text generation, and'),\n",
       " Document(page_content='sentiment analysis.\\n\\n    \\\\subsection{History of LLMs}\\n\\nThe'),\n",
       " Document(page_content='earliest LLMs were developed in the 1980s and 1990s, but'),\n",
       " Document(page_content='they were limited by the amount of data that could be'),\n",
       " Document(page_content='processed and the computational power available at the'),\n",
       " Document(page_content='time. In the past decade, however, advances in hardware and'),\n",
       " Document(page_content='software have made it possible to train LLMs on massive'),\n",
       " Document(page_content='datasets, leading to significant improvements in'),\n",
       " Document(page_content='performance.'),\n",
       " Document(page_content='\\\\subsection{Applications of LLMs}\\n\\nLLMs have many'),\n",
       " Document(page_content='applications in the industry, including chatbots, content'),\n",
       " Document(page_content='creation, and virtual assistants. They can also be used in'),\n",
       " Document(page_content='academia for research in linguistics, psychology, and'),\n",
       " Document(page_content='computational linguistics.\\n\\n\\\\end{document}')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "latex_text = \"\"\"\n",
    "\n",
    "    \\documentclass{article}\n",
    "\n",
    "    \\begin{document}\n",
    "\n",
    "    \\maketitle\n",
    "\n",
    "    \\section{Introduction}\n",
    "\n",
    "    Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in various natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
    "\n",
    "    \\subsection{History of LLMs}\n",
    "\n",
    "The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
    "\n",
    "\\subsection{Applications of LLMs}\n",
    "\n",
    "LLMs have many applications in the industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "latex_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.LATEX, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "latex_docs = latex_splitter.create_documents([latex_text])\n",
    "latex_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc7883-1caa-4fd1-b7fc-6bab52efca8b",
   "metadata": {},
   "source": [
    "## Embed Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8f1e9cf-9542-4519-b6c5-12f3348f35e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06722454, -0.023729993, 0.017487843, -0.013195328, -0.039584607]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "\n",
    "embed_params = {\n",
    "    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "    EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"skills-network\",\n",
    "    params=embed_params,\n",
    ")\n",
    "query = \"How are you?\"\n",
    "\n",
    "query_result = watsonx_embedding.embed_query(query)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b197b7a-2bcb-476a-8c86-d6e3af0a5d91",
   "metadata": {},
   "source": [
    "## Create and Configure Vector Databases to Store Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d91c8a-2de6-4ae4-8abd-0b86e25b06e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='Smoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Designated Smoking Areas: Smoking is only permitted in designated smoking areas, as marked by'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='No Smoking in Company Vehicles: Smoking is not permitted in company vehicles, whether they are'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Policy Purpose: The Smoking Policy has been established to provide clear guidance and expectations')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader(\"companypolicies.txt\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "ids = [str(i) for i in range(0, len(chunks))]\n",
    "vectordb = Chroma.from_documents(chunks, watsonx_embedding, ids=ids)\n",
    "\n",
    "query = \"Smoking policy\"\n",
    "docs = vectordb.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dc12f-2ee3-4a2e-a15f-9decc1ec1bc4",
   "metadata": {},
   "source": [
    "## Develop a retriever to fetch document segments based on queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3700bd-99ca-4068-8e8b-59f36c073586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-24 22:23:35--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6363 (6.2K) [text/plain]\n",
      "Saving to: ‘new-Policies.txt’\n",
      "\n",
      "new-Policies.txt    100%[===================>]   6.21K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-05-24 22:23:35 (297 MB/s) - ‘new-Policies.txt’ saved [6363/6363]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='to this policy. Non-compliance may lead to appropriate disciplinary action, which could include'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\"\n",
    "loader = TextLoader(\"new-Policies.txt\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data) \n",
    "vectordb = Chroma.from_documents(documents=chunks, embedding=watsonx_embedding)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\":2})\n",
    "query = \"Email policy\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8c125-2dc9-4bb9-ab82-383de7c81b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
