{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.12/site-packages (19.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 23:41:48.972640: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-03 23:41:48.974057: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 23:41:48.979100: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 23:41:48.992147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743723709.018646     299 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743723709.024969     299 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743723709.042130     299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743723709.042163     299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743723709.042165     299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743723709.042168     299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-03 23:41:49.047467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1)\n",
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "print(data.shape)\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - loss: 10.2376 \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.2444 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.2389 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1384 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1519 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1379 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1089 \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1134\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1080 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0989 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0962 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0770\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0968 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0691 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0761 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0740 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0636 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0516 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0428 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0432 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f03b01f0500>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 316ms/step - loss: 0.0053\n",
      "Test loss: 0.004456649534404278\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 325ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')\n",
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(scaler.inverse_transform(data), label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 320ms/step - loss: 0.3720\n",
      "Test loss 0.5248480439186096\n"
     ]
    }
   ],
   "source": [
    "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
    "dropout = Dropout(0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1)(dropout)\n",
    "\n",
    "#Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 644ms/step - loss: 3.7734  \n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 631ms/step - loss: 0.7579 \n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 626ms/step - loss: 0.1808 \n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0635 \n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 631ms/step - loss: 0.0375 \n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0320 \n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - loss: 0.0306 \n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - loss: 0.0295 \n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - loss: 0.0216 \n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - loss: 0.0181 \n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0174 \n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 636ms/step - loss: 0.0185 \n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0162 \n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 602ms/step - loss: 0.0180 \n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 633ms/step - loss: 0.0205 \n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 635ms/step - loss: 0.0200 \n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0137 \n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0135 \n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - loss: 0.0158 \n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0185 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 314ms/step - loss: 0.0039\n",
      "Test loss with batch size 16: 0.002434160327538848\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - loss: 7.4487 \n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 1.5202 \n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 1.1512\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.8008\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.5348\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.3471\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.1980\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.1056\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0706\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 0.0539\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0455\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0373\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0341\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0234\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0234\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0209\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0189\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0208\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0174\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0139\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 314ms/step - loss: 7.9979e-04\n",
      "Test loss with batch size 64: 0.0015250942669808865\n"
     ]
    }
   ],
   "source": [
    "def reset_model(model):\n",
    "    model_clone = tf.keras.models.clone_model(model) \n",
    "    model_clone.set_weights(model.get_weights())\n",
    "    return model_clone\n",
    "    \n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "initial_model = reset_model(model)\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "model = reset_model(initial_model)\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - loss: 0.3990 \n",
      "Epoch 2/20\n",
      "\u001b[1m24/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 0.2863 "
     ]
    }
   ],
   "source": [
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
